{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13297823,"sourceType":"datasetVersion","datasetId":8428377},{"sourceId":13298790,"sourceType":"datasetVersion","datasetId":8429102}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport xml.etree.ElementTree as ET\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport random\nimport pandas as pd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"datapath = \"/kaggle/input/whiteflydataset08102025/Cassava Whitefly Dataset\"\nlow_abundance = f\"{datapath}/low_abundance\"\nmoderate_abundance = f\"{datapath}/moderate_abundance\"\nsuper_abundance = f\"{datapath}/super_abundance\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categories = {\n    \"low\": low_abundance,\n    \"moderate\": moderate_abundance,\n    \"super\": super_abundance\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to parse annotation XML (Pascal VOC format)\ndef parse_annotation(xml_file):\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n    objects = []\n    for obj in root.findall(\"object\"):\n        label = obj.find(\"name\").text\n        bbox = obj.find(\"bndbox\")\n        xmin = int(bbox.find(\"xmin\").text)\n        ymin = int(bbox.find(\"ymin\").text)\n        xmax = int(bbox.find(\"xmax\").text)\n        ymax = int(bbox.find(\"ymax\").text)\n        objects.append({\"label\": label, \"bbox\": (xmin, ymin, xmax, ymax)})\n    return objects","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Collect dataset stats\nstats = []\nfor cat, path in categories.items():\n    img_dir = os.path.join(path, \"images\")\n    ann_dir = os.path.join(path, \"annotation\")\n    \n    img_files = glob.glob(f\"{img_dir}/*.jpg\")\n    ann_files = glob.glob(f\"{ann_dir}/*.xml\")\n    \n    for ann in ann_files:\n        objects = parse_annotation(ann)\n        stats.append({\n            \"category\": cat,\n            \"file\": os.path.basename(ann),\n            \"num_whiteflies\": len(objects)\n        })\n\ndf = pd.DataFrame(stats)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Dataset Summary ---\nprint(\"Dataset Summary:\")\nprint(df.groupby(\"category\")[\"num_whiteflies\"].describe())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Count distribution per category ---\nplt.figure(figsize=(10,5))\nsns.boxplot(x=\"category\", y=\"num_whiteflies\", data=df, palette=\"Set2\")\nplt.title(\"Whitefly Count Distribution per Category\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Histogram of counts ---\nplt.figure(figsize=(10,5))\nsns.histplot(df[\"num_whiteflies\"], bins=50, kde=True)\nplt.title(\"Distribution of Whitefly Counts Across All Images\")\nplt.xlabel(\"Number of Whiteflies per Image\")\nplt.ylabel(\"Frequency\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Sample visualization with bounding boxes ---\ndef show_random_samples(category, n=3):\n    img_dir = os.path.join(categories[category], \"images\")\n    ann_dir = os.path.join(categories[category], \"annotation\")\n    \n    img_files = glob.glob(f\"{img_dir}/*.jpg\")\n    sample_files = random.sample(img_files, n)\n    \n    for img_file in sample_files:\n        ann_file = os.path.join(ann_dir, os.path.basename(img_file).replace(\".jpg\", \".xml\"))\n        objects = parse_annotation(ann_file)\n        \n        img = cv2.imread(img_file)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        for obj in objects:\n            (xmin, ymin, xmax, ymax) = obj[\"bbox\"]\n            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (255,0,0), 2)\n        \n        plt.figure(figsize=(6,6))\n        plt.imshow(img)\n        plt.title(f\"{category} - {len(objects)} whiteflies\")\n        plt.axis(\"off\")\n        plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show random samples from each category\nfor cat in categories.keys():\n    show_random_samples(cat, n=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Class imbalance check ---\nclass_counts = df.groupby(\"category\")[\"file\"].count().reset_index()\nclass_counts.columns = [\"category\", \"num_images\"]\n\nplt.figure(figsize=(6,4))\nsns.barplot(x=\"category\", y=\"num_images\", data=class_counts, palette=\"viridis\")\nplt.title(\"Number of Images per Category\")\nplt.ylabel(\"Image Count\")\nplt.show()\n\nprint(\"Image counts per category:\\n\", class_counts)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport shutil\nimport xml.etree.ElementTree as ET\nimport cv2\n\n# Paths\ndatapath = \"/kaggle/input/whiteflydataset08102025/Cassava Whitefly Dataset\"\ncategories = [\"low_abundance\", \"moderate_abundance\", \"super_abundance\"]\n\n# Output path\nout_path = \"/kaggle/working/whitefly_yolo\"\nimg_out = os.path.join(out_path, \"images\")\nlbl_out = os.path.join(out_path, \"labels\")\n\nfor split in [\"train\", \"val\", \"test\"]:\n    os.makedirs(os.path.join(img_out, split), exist_ok=True)\n    os.makedirs(os.path.join(lbl_out, split), exist_ok=True)\n\n# Function: VOC → YOLO\ndef voc_to_yolo(xml_file, img_w, img_h):\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n    yolo_labels = []\n    for obj in root.findall(\"object\"):\n        bbox = obj.find(\"bndbox\")\n        xmin = int(bbox.find(\"xmin\").text)\n        ymin = int(bbox.find(\"ymin\").text)\n        xmax = int(bbox.find(\"xmax\").text)\n        ymax = int(bbox.find(\"ymax\").text)\n\n        # Convert to YOLO format\n        x_center = ((xmin + xmax) / 2) / img_w\n        y_center = ((ymin + ymax) / 2) / img_h\n        width = (xmax - xmin) / img_w\n        height = (ymax - ymin) / img_h\n\n        yolo_labels.append(f\"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n    return yolo_labels\n\n# Collect all image/annotation pairs\nall_data = []\nfor cat in categories:\n    img_dir = os.path.join(datapath, cat, \"images\")\n    ann_dir = os.path.join(datapath, cat, \"annotation\")\n    img_files = glob.glob(f\"{img_dir}/*.jpg\")\n    for img_file in img_files:\n        ann_file = os.path.join(ann_dir, os.path.basename(img_file).replace(\".jpg\", \".xml\"))\n        if os.path.exists(ann_file):\n            all_data.append((img_file, ann_file))\n\nprint(f\"Total images with annotations: {len(all_data)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Shuffle and split\nrandom.shuffle(all_data)\nn = len(all_data)\ntrain_split = int(0.7 * n)\nval_split = int(0.9 * n)\n\nsplits = {\n    \"train\": all_data[:train_split],\n    \"val\": all_data[train_split:val_split],\n    \"test\": all_data[val_split:]\n}\n\n# Process and copy\nfor split, items in splits.items():\n    for img_file, ann_file in items:\n        # Read image size\n        img = cv2.imread(img_file)\n        if img is None: \n            continue\n        h, w = img.shape[:2]\n\n        # Convert annotation\n        labels = voc_to_yolo(ann_file, w, h)\n\n        # Save image\n        out_img = os.path.join(img_out, split, os.path.basename(img_file))\n        shutil.copy(img_file, out_img)\n\n        # Save label\n        out_lbl = os.path.join(lbl_out, split, os.path.basename(img_file).replace(\".jpg\", \".txt\"))\n        with open(out_lbl, \"w\") as f:\n            f.write(\"\\n\".join(labels))\n\nprint(\"✅ Dataset prepared in YOLO format at:\", out_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create dataset.yaml file in /kaggle/working/\nyaml_content = \"\"\"path: /kaggle/working/whitefly_yolo\ntrain: images/train\nval: images/val\ntest: images/test\n\nnc: 1\nnames: ['whitefly']\n\"\"\"\n\nwith open('/kaggle/working/dataset.yaml', 'w') as f:\n    f.write(yaml_content)\n\nprint(\"✅ dataset.yaml file created successfully at /kaggle/working/\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"_kg_hide-input":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YOLO(\"yolo11m.pt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train\nmodel.train(\n    data=\"/kaggle/working/dataset.yaml\",\n    epochs=100,\n    imgsz=1280,\n    batch=32,\n    workers=2,\n    patience=60,           # early stop if no improvement\n    lr0=0.002,             # learning rate\n    optimizer='AdamW',\n    augment=True,\n    rect=False,            # enables shuffle\n    device=0,\n    save=True,\n    plots=True,\n    cache=True,\n    project=\"/kaggle/working/whitefly_yolo\",\n    name=\"whitefly_combined_train\",\n    mosaic=1.0,\n    mixup=0.2,\n    copy_paste=0.1,\n    hsv_h=0.015,\n    hsv_s=0.7,\n    hsv_v=0.4,\n    fliplr=0.5,\n    flipud=0.3\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save best model path\nbest_model_path = model.ckpt_path\nprint(\"Best model saved at:\", best_model_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YOLO(\"/kaggle/working/whitefly_yolo/whitefly_combined_train2/weights/best.pt\")\nmetrics = model.val()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test image\ncustom_dir = \"/kaggle/input/whitefly-test/WhatsApp Image 2025-10-08 at 08.19.44_3b6448df.jpg\"\n\n# Run prediction\nresults = model.predict(\n    source=custom_dir,\n    imgsz=960,\n    conf=0.20,\n    max_det=2000,\n    save=False\n)\n\n# Get first result\nr = results[0]\nimg = cv2.imread(custom_dir)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# Draw smaller bounding boxes\nshrink_ratio = 0.8  # adjust to make boxes smaller or larger\nfor idx, box in enumerate(r.boxes.xyxy, start=1):\n    x1, y1, x2, y2 = map(int, box)\n\n    # Calculate width and height\n    w = x2 - x1\n    h = y2 - y1\n\n    # Shrink the box around its center\n    cx = x1 + w // 2\n    cy = y1 + h // 2 \n    w_new = int(w * shrink_ratio)\n    h_new = int(h * shrink_ratio)\n    x1_new = cx - w_new // 2\n    y1_new = cy - h_new // 2\n    x2_new = cx + w_new // 2\n    y2_new = cy + h_new // 2\n\n    cv2.rectangle(img, (x1_new, y1_new), (x2_new, y2_new), (255, 0, 0), 2)\n    # cv2.putText(img, str(idx), (x1_new, y1_new - 10),\n    #             cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n\n# Count detections\ncount = len(r.boxes)\n\n# Show image\nplt.figure(figsize=(10,10))\nplt.imshow(img)\nplt.axis(\"off\")\nplt.title(f\"Total Whiteflies Detected: {count}\")\nplt.show()\n\n# Save the annotated image\noutput_path = \"/kaggle/working/whitefly_detection_small_boxes.jpg\"\n# Convert back to BGR for OpenCV saving\nimg_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\ncv2.imwrite(output_path, img_bgr)\n\nprint(f\"Annotated image saved at: {output_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"precision = metrics.box.p[0]    # precision for class 0\nrecall = metrics.box.r[0]       # recall for class 0\nmap50 = metrics.box.map50       # mAP@0.5 (global)\nmap95 = metrics.box.map         # mAP@0.5:0.95 (global)\n\n# F1-score\nf1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall:    {recall:.4f}\")\nprint(f\"F1-score:  {f1:.4f}\")\nprint(f\"mAP@0.5:   {map50:.4f}\")\nprint(f\"mAP@0.5:0.95: {map95:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}